=== ./src/lib.rs ===
pub mod client;
pub mod core;
pub mod vendors;
pub mod utils;
// pub mod isolate;


=== ./src/main.rs ===
mod client;
mod core;
mod utils;
mod vendors;
mod worker;

use crate::client::redis::RedisClient;
use crate::core::server::server;
use crate::worker::Worker;
use tokio;

#[tokio::main(flavor = "multi_thread", worker_threads = 20)] 
async fn main() {


    // Initialize Redis client
    let redis_client = RedisClient::new("redis://127.0.0.1/")
        .expect("Failed to connect to Redis");

    // Start the worker
    let worker_redis = redis_client.clone();
    tokio::spawn(async move {
        let worker = Worker::new(worker_redis);
        worker.start(20).await;
    });
    

    // Start the server
    let app = server(redis_client);

    let listener = tokio::net::TcpListener::bind("0.0.0.0:3001")
        .await
        .unwrap();

    println!("Server running on http://0.0.0.0:3001");
    axum::serve(listener, app).await.unwrap();
}

=== ./src/client/mod.rs ===
pub mod redis;


=== ./src/client/redis.rs ===
use bincode;
use deadpool_redis::{redis, Config, Connection, Pool, Runtime};
use redis::{AsyncCommands, RedisError, RedisResult};
use serde::{de::DeserializeOwned, Serialize};
use std::time::{Duration, SystemTime, UNIX_EPOCH};

#[derive(Clone)]
pub struct RedisClient {
    pool: Pool,
}

impl RedisClient {
    pub fn new(redis_url: &str) -> RedisResult<Self> {
        let cfg = Config::from_url(redis_url);
        let pool = cfg
            .create_pool(Some(Runtime::Tokio1))
            .map_err(|e| RedisError::from((redis::ErrorKind::IoError, "Pool creation error check the url")))?;
        Ok(Self { pool })
    }

    async fn get_conn(&self) -> RedisResult<Connection> {
        self.pool
            .get()
            .await
            .map_err(|_| RedisError::from((redis::ErrorKind::IoError, "getting connection error")))
    }

    pub async fn store_job<T: Serialize>(
        &self,
        key: &str,
        value: &T,
        ttl: Option<Duration>,
    ) -> RedisResult<()> {
        let mut conn = self.get_conn().await?;
        let serialized = bincode::serialize(value).unwrap();


        if let Some(ttl) = ttl {
            conn.set_ex(key, serialized, ttl.as_secs() as usize).await
        } else {
            conn.set(key, serialized).await
        }
    }

    #[tracing::instrument(skip_all)]
    pub async fn get_job<T: DeserializeOwned>(&self, key: &str) -> RedisResult<Option<T>> {
        let mut conn = self.get_conn().await?;
        let data: Option<Vec<u8>> = conn.get(key).await?;

        data.map(|d| bincode::deserialize(&d))
            .transpose()
            .map_err(|e| {
                redis::RedisError::from((
                    redis::ErrorKind::TypeError,
                    "deserialization failed",
                    e.to_string(),
                ))
            })
    }

    pub async fn enqueue_job<T: Serialize>(&self, queue: &str, value: &T) -> RedisResult<()> {
        let mut conn = self.get_conn().await?;
        let serialized = bincode::serialize(value).unwrap(); // Serialize using bincode
        conn.rpush(queue, serialized).await
    }

    pub async fn get_job_from_queue<T: DeserializeOwned>(
        &self,
        queue: &str,
    ) -> RedisResult<Option<T>> {
        let mut conn = self.get_conn().await?;

        // Use BRPOP with 1-second timeout to block until job arrives
        let result: Option<(String, Vec<u8>)> = conn.brpop(queue, 10).await?;

        match result {
            Some((_list_name, data)) => {
                // Deserialize the binary data
                let job = bincode::deserialize(&data).map_err(|e| {
                    redis::RedisError::from((
                        redis::ErrorKind::TypeError,
                        "deserialization failed",
                        e.to_string(),
                    ))
                })?;
                Ok(Some(job))
            }
            None => {
                Ok(None)
            }
        }
    }

    pub async fn create_job<T: Serialize>(
        &self,
        key: &str,
        queue: &str,
        value: &T,
    ) -> RedisResult<()> {
        let mut conn = self.get_conn().await?;
        let serialized = bincode::serialize(value).unwrap(); // Serialize using bincode

        // Store the job in Redis and enqueue it
        redis::pipe()
            .atomic()
            .set(key, &serialized)
            .ignore()
            .rpush(queue, &serialized)
            .ignore()
            .query_async(&mut conn)
            .await
    }
}


=== ./src/core/job.rs ===
use serde::{Deserialize, Serialize};
use uuid::Uuid;
use std::{
    fmt::Display,
    time::{SystemTime, UNIX_EPOCH},
};

use super::{ExecutionSettings, Language};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Job {
    pub id: u64,
    pub source_code: String,
    pub language: Language,
    pub stdin: String,
    pub expected_output: String,
    pub settings: ExecutionSettings,
    pub status: JobStatus,
    pub created_at: i64,         
    pub started_at: Option<i64>, 
    pub finished_at: Option<i64>,
    pub output: JobOutput,
    pub number_of_runs: u8,
}

#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct JobOutput {
    pub stdout: Option<String>,
    pub stderr: Option<String>,
    pub compile_output: Option<String>,
    pub time: Option<f64>,
    pub memory: Option<u64>,
    pub exit_code: Option<i32>,
    pub message: Option<String>,
}

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum JobStatus {
    Queued,
    Processing,
    Accepted,
    WrongAnswer,
    TimeLimitExceeded,
    CompilationError,
    RuntimeError(String),
    InternalError,
    ExecFormatError,
}

impl JobStatus {
    pub fn id(&self) -> i32 {
        match self {
            JobStatus::Queued => 1,
            JobStatus::Processing => 2,
            JobStatus::Accepted => 3,
            JobStatus::WrongAnswer => 4,
            JobStatus::TimeLimitExceeded => 5,
            JobStatus::CompilationError => 6,
            JobStatus::RuntimeError(e) => match e.as_str() {
                "SIGSEGV" => 7,
                "SIGXFSZ" => 8,
                "SIGFPE" => 9,
                "SIGABRT" => 10,
                "NZEC" => 11,
                _ => 12,
            },
            JobStatus::InternalError => 13,
            JobStatus::ExecFormatError => 14,
        }
    }
}

impl Display for JobStatus {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            JobStatus::Queued => write!(f, "In Queue"),
            JobStatus::Processing => write!(f, "Processing"),
            JobStatus::Accepted => write!(f, "Accepted"),
            JobStatus::WrongAnswer => write!(f, "Wrong Answer"),
            JobStatus::TimeLimitExceeded => write!(f, "Time Limit Exceeded"),
            JobStatus::CompilationError => write!(f, "Compilation Error"),
            JobStatus::RuntimeError(e) => write!(f, "Runtime Error: ({})", e),
            JobStatus::InternalError => write!(f, "Internal Error"),
            JobStatus::ExecFormatError => write!(f, "Exec Format Error"),
        }
    }
}

impl Job {
    pub fn new(source_code: String, language: Language) -> Self {
        Self {
            id: Uuid::new_v4().as_u128() as u64,
            source_code,
            language,
            ..Default::default()
        }
    }

    pub fn with_stdin(mut self, stdin: String) -> Self {
        self.stdin = stdin;
        self
    }

    pub fn with_expected_output(mut self, expected_output: String) -> Self {
        self.expected_output = expected_output;
        self
    }

    pub fn set_limits(
        mut self,
        cpu_time_limit: f64,
        memory_limit: u64,
        stack_limit: u64,
        max_processes: u32,
    ) -> Self {
        self.settings.cpu_time_limit = cpu_time_limit;
        self.settings.memory_limit = memory_limit;
        self.settings.stack_limit = stack_limit;
        self.settings.max_processes = max_processes;
        self
    }
}

impl Default for Job {
    fn default() -> Self {
        Self {
            id: 0,
            source_code: String::new(),
            language: Language::default(),
            stdin: String::new(),
            expected_output: String::new(),
            settings: ExecutionSettings::default(),
            status: JobStatus::Queued,
            created_at: SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .unwrap()
                .as_secs() as i64,
            started_at: None,
            finished_at: None,
            output: JobOutput::default(),
            number_of_runs: 5,
        }
    }
}


=== ./src/core/language.rs ===
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Language {
    pub name: String,
    pub source_file: String,
    pub compile_cmd: Option<String>,
    pub run_cmd: String,
    pub is_compiled: bool,
}

impl Default for Language {
    fn default() -> Self {
        Self {
            name: "python".to_string(),
            source_file: "main.py".to_string(),
            compile_cmd: None,
            run_cmd: "/usr/bin/python3 main.py".to_string(),
            is_compiled: false,
        }
    }
}

=== ./src/core/mod.rs ===
pub mod job;
pub mod language;
pub mod settings;
pub mod server;

pub use job::*;
pub use language::*;
pub use settings::*;

=== ./src/core/pool.rs ===
use serde::{Deserialize, Serialize};
use std::time::SystemTime;
use thiserror::Error;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Job {
    pub id: u128,
    pub source_code: String,
    pub language: Language,
    pub stdin: String,
    pub expected_output: String,
    pub settings: ExecutionSettings,
    pub status: JobStatus,
    pub created_at: SystemTime,
    pub started_at: Option<SystemTime>,
    pub finished_at: Option<SystemTime>,
    pub output: JobOutput,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct JobOutput {
    pub stdout: Option<String>,
    pub stderr: Option<String>,
    pub compile_output: Option<String>,
    pub time: Option<f64>,
    pub memory: Option<u64>,
    pub exit_code: Option<i32>,
}

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum JobStatus {
    Queued,
    Processing,
    Completed,
    Failed(String),
}

#[derive(Error, Debug)]
pub enum JobError {
    #[error("Invalid job configuration")]
    ConfigurationError,
    #[error("Execution timeout")]
    TimeoutError,
    #[error("Memory limit exceeded")]
    MemoryLimitExceeded,
    #[error("Compilation failed: {0}")]
    CompilationError(String),
    #[error("Runtime error: {0}")]
    RuntimeError(String),
}


impl Job {
    pub fn new(source_code: String, language: Language) -> Self {
        Self {
            id: rand::random(),
            source_code,
            language,
            ..Default::default()
        }
    }

    pub fn validate(&self) -> Result<(), JobError> {
        if self.source_code.is_empty() {
            return Err(JobError::ConfigurationError);
        }
        Ok(())
    }
}

impl Default for Job {
    fn default() -> Self {
        Self {
            id: rand::random(),
            source_code: String::new(),
            language: Language::default(),
            stdin: String::new(),
            expected_output: String::new(),
            settings: ExecutionSettings::default(),
            status: JobStatus::Queued,
            created_at: SystemTime::now(),
            started_at: None,
            finished_at: None,
            output: JobOutput::default(),
        }
    }
}

=== ./src/core/server.rs ===
use crate::{
    client::redis::RedisClient,
    core::{job::Job, language::Language, settings::ExecutionSettings},
    utils::utils::{check_job, create_job},
    vendors::debugger,
};
use axum::{
    extract::{Json, Path, State},
    http::StatusCode,
    routing::{get, post},
    Router,
};
use serde_json::json;
use std::sync::Arc;

pub fn server(redis_client: RedisClient) -> Router {
    Router::new()
        .route("/create", post(handle_create))
        .route("/check/:job_id", get(handle_check))
        .route("/debug", post(handle_debug))
        .with_state(Arc::new(redis_client))
}

#[derive(serde::Deserialize)]
struct CreateJobRequest {
    code: String,
    language: String,
    input: String,
    expected: String,
    time_limit: Option<f64>,
    memory_limit: Option<u64>,
    stack_limit: Option<u64>,
}

async fn handle_create(
    State(redis): State<Arc<RedisClient>>,
    Json(payload): Json<CreateJobRequest>,
) -> Result<Json<serde_json::Value>, StatusCode> {
    let language = match payload.language.as_str() {
        "python" => Language {
            name: "python".to_string(),
            source_file: "main.py".to_string(),
            compile_cmd: None,
            run_cmd: "/usr/bin/python3 main.py".to_string(),
            is_compiled: false,
        },
        "cpp" => Language {
            name: "cpp".to_string(),
            source_file: "main.cpp".to_string(),
            compile_cmd: Some("/usr/bin/g++ main.cpp".to_string()),
            run_cmd: "./a.out".to_string(),
            is_compiled: true,
        },
        "javascript" => Language {
            name: "javascript".to_string(),
            source_file: "main.js".to_string(),
            compile_cmd: None,
            run_cmd: "/usr/bin/node main.js".to_string(),
            is_compiled: false,
        },
        "java" => Language {
            name: "java".to_string(),
            source_file: "Main.java".to_string(),
            compile_cmd: Some("/usr/bin/javac Main.java".to_string()),
            run_cmd: "/usr/bin/java Main".to_string(),
            is_compiled: false,
        },
        "sql" => Language {
            name: "sql".to_string(),
            source_file: "main.sql".to_string(),
            compile_cmd: None,
            run_cmd: "sqlite3".to_string(),
            is_compiled: false,
        },
        _ => return Err(StatusCode::BAD_REQUEST),
    };

    let settings = ExecutionSettings {
        cpu_time_limit: payload.time_limit.unwrap_or(2.0),
        memory_limit: payload.memory_limit.unwrap_or(128_000),
        stack_limit: payload.stack_limit.unwrap_or(64_000),
        ..Default::default()
    };

    let job = Job::new(payload.code, language)
        .with_stdin(payload.input)
        .with_expected_output(payload.expected)
        .set_limits(
            settings.cpu_time_limit,
            settings.memory_limit,
            settings.stack_limit,
            60,
        );

    let job_id = create_job(&redis, job)
        .await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;

    Ok(Json(json!({ "status": "created", "id": job_id })))
}

async fn handle_check(
    State(redis): State<Arc<RedisClient>>,
    Path(job_id): Path<String>,
) -> Result<Json<serde_json::Value>, StatusCode> {
    let job = check_job(&redis, &job_id)
        .await
        .map_err(|_| StatusCode::NOT_FOUND)?;

    let send_output = &json!({
        "stdout": job.output.stdout.unwrap_or("".to_string()),
        "time": job.output.time.unwrap_or(0.0),
        "memory": job.output.memory.unwrap_or(0),
        "stderr": job.output.stderr.unwrap_or("".to_string()),
        "token": job.id,
        "compile_output": job.output.compile_output.unwrap_or("".to_string()),
        "message": job.output.message.unwrap_or("".to_string()),
        "status": {
            "id": job.status.id(),
            "description": format!("{}",job.status),
        },
    });

    println!("Job status: {}", send_output);

    Ok(Json(json!(send_output)))
}

async fn handle_debug(
    Json(body): Json<debugger::DebugRequest>,
) -> Result<Json<serde_json::Value>, StatusCode> {
    let response = debugger::debug(axum::Json(body))
        .await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;
    Ok(Json(json!(*response)))
}


=== ./src/core/settings.rs ===
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExecutionSettings {
    pub cpu_time_limit: f64,
    pub wall_time_limit: f64,
    pub memory_limit: u64,
    pub stack_limit: u64,
    pub max_processes: u32,
    pub max_file_size: u64,
    pub enable_network: bool,
}

impl Default for ExecutionSettings {
    fn default() -> Self {
        Self {
            cpu_time_limit: 2.0,
            wall_time_limit: 5.0,
            memory_limit: 128_000,
            stack_limit: 64_000,
            max_processes: 60,
            max_file_size: 4096,
            enable_network: false,
        }
    }
}

=== ./src/utils/cleanup.sh ===
id=$0
rm -rf $id

=== ./src/utils/mod.rs ===
pub mod utils;  

=== ./src/utils/compile.sh ===
#!/bin/bash
# compile.sh
case "$LANGUAGE" in
    "python")
        python3 -m py_compile code.py
        ;;
    "cpp")
        g++ -O2 -w -std=c++17 code.cpp -o program
        ;;
    "c")
        gcc -O2 -w -std=c11 code.c -o program
        ;;
    *)
        echo "Unsupported language"
        exit 1
        ;;
esac


=== ./src/utils/run_script.sh ===
#!/bin/bash
# run.sh
case "$LANGUAGE" in
    "python")
        python3 code.py
        ;;
    "cpp"|"c")
        ./program
        ;;
    *)
        echo "Unsupported language"
        exit 1
        ;;
esac

=== ./src/utils/utils.rs ===
use std::time::{SystemTime, UNIX_EPOCH};

use crate::{client::redis::RedisClient, core::job::Job};
use serde_json;

/// Creates a new job and stores it in Redis.
pub async fn create_job(redis: &RedisClient, job: Job) -> Result<String, String> {
    let job_id = job.id.to_string();


    redis
        .store_job(&job_id, &job, None)
        .await
        .map_err(|e| e.to_string())?;

    redis
        .enqueue_job("jobs", &job)
        .await
        .map_err(|e| e.to_string())?;

    Ok(job_id)
}

/// Retrieves a job from Redis by its ID.
pub async fn check_job(redis: &RedisClient, job_id: &str) -> Result<Job, String> {
    let data=redis
        .get_job(job_id)
        .await
        .map_err(|e| e.to_string());
    match data {
        Ok(Some(job)) => Ok(job),
        Ok(None) => Err("Job not found".to_string()),
        Err(e) => Err(e),
    }
}


=== ./src/vendors/debugger.rs ===
use std::{collections::HashMap, fs::File, io::Write, process::Stdio};
use tokio::process::Command;

use axum::{http::StatusCode, Json};
// use tempfile::NamedTempFile;


#[derive(Debug, serde::Serialize, serde::Deserialize,)]
struct ExecutionOutput {
    stdout: String,
    stderr: String,
}

#[derive(serde::Deserialize, serde::Serialize)]
pub struct DebugRequest {
    code: String,
    language: String,
    input: String,
}

#[derive(serde::Serialize, Debug, serde::Deserialize)]
struct DebugStep {
    step: usize,
    line: u32,
    variables: HashMap<String, String>,
    stdout: String,
}

#[derive(serde::Serialize, serde::Deserialize)]
pub struct DebugResponse {
    steps: Vec<DebugStep>,
}

#[derive(Debug)]
enum ExecutionError {
    DebugParseError,
    ExecutionFailed
}

pub async fn debug(
    Json(payload): Json<DebugRequest>,
) -> Result<Json<DebugResponse>, StatusCode> {
    // Validate language
    if payload.language != "python" {
        return Err(StatusCode::BAD_REQUEST);
    }

    // Execute code with debug tracing
    let steps = execute_with_debug(&payload.code, &payload.input)
        .await
        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;

    Ok(Json(DebugResponse { steps }))
}

async fn execute_with_debug(code: &str, input: &str) -> Result<Vec<DebugStep>, ExecutionError> {
 tokio::fs::write("debugger/temp.py", code)
     .await
     .map_err(|_| ExecutionError::DebugParseError)?;

 let file_path = "debugger/temp.py";
    

 // Call the Python script
 let output = Command::new("python3")
     .arg("./debugger/debug.py")
     .arg(file_path)
     .stdout(Stdio::piped())
     .stderr(Stdio::piped())
     .output()
     .await
     .map_err(|_| ExecutionError::ExecutionFailed)?;

println!("stdout: {}", String::from_utf8_lossy(&output.stdout));
println!("stderr: {}", String::from_utf8_lossy(&output.stderr));


 // Parse the output
 let stdout = String::from_utf8(output.stdout).map_err(|_| ExecutionError::ExecutionFailed)?;
 let steps: Vec<DebugStep> = serde_json::from_str(&stdout)
     .map_err(|_| ExecutionError::DebugParseError)?;

 Ok(steps)
}


async fn run_python_code(code: &str, input: &str) -> Result<ExecutionOutput, ExecutionError> {
    // Create a temporary file to store the Python code
    let wrapper_path="debugger/debug.py";
    let code_path="debugger/temp.py";
    let input_path="debugger/temp_input.txt";
    tokio::fs::write(code_path, code)
        .await
        .map_err(|_| ExecutionError::DebugParseError)?;
    tokio::fs::write(input_path, input)
        .await
        .map_err(|_| ExecutionError::DebugParseError)?;


    let input_file=File::open(input_path).unwrap();

    let child = Command::new("python3")
        .arg(code_path)
        .stdin(input_file)
        .output()
        .await
        .map_err(|_| ExecutionError::DebugParseError)?;

    println!("stdout: {}", String::from_utf8_lossy(&child.stdout));
    println!("stderr: {}", String::from_utf8_lossy(&child.stderr));

    Ok(ExecutionOutput {
        stdout: String::from_utf8_lossy(&child.stdout).to_string(),
        stderr: String::from_utf8_lossy(&child.stderr).to_string(),
    })
}


=== ./src/vendors/isolate.rs ===
use crate::{
    client::redis::RedisClient,
    core::{Job, JobStatus},
};
use redis::RedisError;
use std::{
    fs::File,
    io::Error,
    time::{SystemTime, UNIX_EPOCH},
};
use tokio::process::Command;

#[derive(Debug)]
pub struct Metadata {
    pub time: f64,
    pub memory: u64,
    pub exit_code: i32,
    pub message: String,
    pub status: String,
}

#[derive(Clone)]
pub struct IsolateExecutor {
    redis: RedisClient,
}

impl IsolateExecutor {
    pub fn new(redis: RedisClient) -> Self {
        Self { redis }
    }
    pub async fn execute(&self, job: &mut Job) -> Result<JobStatus, Error> {
        let box_id = job.id % 2147483647;
        job.status = JobStatus::Processing;
        job.started_at = Some(
            SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .unwrap()
                .as_secs()
                .try_into()
                .unwrap(),
        );

        // Initialize new box
        let init_output = tokio::task::spawn_blocking(move || {
            std::process::Command::new("isolate")
                .args(&["-b", &box_id.to_string(), "--init"])
                .output()
        })
        .await
        .map_err(|e| format!("Failed to initialize box: {:?}", e))
        .unwrap()?;


        let box_path = String::from_utf8_lossy(&init_output.stdout)
            .trim()
            .to_string();

        let file_path = format!("{}/box", box_path);
        let stdin_file = format!("{}/stdin", file_path);
        let stdout_file = format!("{}/stdout", file_path);
        let stderr_file = format!("{}/stderr", file_path);
        let metadata_file = format!("{}/metadata", file_path);

        // Write source code
        let source_path = format!("{}/{}", file_path, job.language.source_file);

        tokio::fs::write(&source_path, &job.source_code)    
            .await
            .expect(format!("Failed to write source code to {}", source_path).as_str());
        tokio::fs::write(&stdin_file, &job.stdin)
            .await
            .expect(format!("Failed to write stdin to {}", stdin_file).as_str());

        let stdin_file =
            File::open(stdin_file).expect(format!("Failed to open stdin file {}", box_id).as_str());
        // let mut stdout_file = File::create(stdout_file)
        //     .expect(format!("Failed to open stdout file {}", box_id).as_str());
        // let mut stderr_file = File::create(stderr_file)
        //     .expect(format!("Failed to open stderr file {}", box_id).as_str());
        File::create(&metadata_file)
            .expect(format!("Failed to open metadata file {}", box_id).as_str());

        // Run compilation if needed
        if let Some(compile_cmd) = &job.language.compile_cmd {
            let compile_parts: Vec<&str> = compile_cmd.split_whitespace().collect();
            let compile_executable = compile_parts[0];
            let compile_args = &compile_parts[1..];

            let compile_status = Command::new("isolate")
                .args(&[
                    "-b",
                    &box_id.to_string(),
                    "-M",
                    metadata_file.as_str(),
                    "--process=60",
                    "-t",
                    "5",
                    "-x",
                    "0",
                    "-w",
                    "10",
                    "-k",
                    "12800",
                    "-f",
                    "1024",
                    "-E",
                    "PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"",
                    "-E",
                    "HOME=/tmp",
                    "-d",
                    "/etc:noexec",
                    "--run",
                    "--",
                    "/usr/bin/sh",
                    "-c",
                    format!(
                        "{} {} 2> /box/compile_output",
                        compile_executable,
                        compile_args.join(" ")
                    )
                    .as_str(),
                ])
                .output()
                .await
                .expect(format!("Failed to compile job {}", job.id).as_str());

            println!("Compilation status: {:?}", compile_status);

            if !compile_status.status.success() {
                let compile_output =
                    tokio::fs::read_to_string(format!("{}/compile_output", file_path))
                        .await
                        .expect(
                            format!("Failed to read compile output for job {}", job.id).as_str(),
                        );

                println!("Compilation error: {}", compile_output);

                job.output.compile_output = Some(compile_output);
                job.status = JobStatus::CompilationError;
                self.update_job_in_redis(job).await.unwrap();
                return Ok(JobStatus::CompilationError);
            }
        }

        let run_parts: Vec<&str> = job.language.run_cmd.split_whitespace().collect();
        let run_executable = run_parts[0];
        let run_args = &run_parts[1..];

        let _ = Command::new("isolate")
            .args(&[
                "-b",
                &box_id.to_string(),
                "-M",
                &metadata_file,
                "--process=60",
                "-t",
                &job.settings.cpu_time_limit.to_string(),
                "-x",
                "0",
                "-w",
                "10",
                "-k",
                "128000",
                "-E",
                "PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"",
                "-E",
                "HOME=/tmp",
                "-d",
                "/etc:noexec",
                "--run",
                "--",
                "/usr/bin/sh",
                "-c",
                format!(
                    "{} {} > /box/stdout 2> /box/stderr",
                    run_executable,
                    run_args.join(" ")
                )
                .as_str(),
            ])
            .stdin(stdin_file)
            .output()
            .await
            .unwrap();

        let stdout_content = tokio::fs::read_to_string(&stdout_file).await.unwrap();
        let stderr_content = tokio::fs::read_to_string(&stderr_file).await.unwrap();


        job.output.stdout = Some(stdout_content);
        job.output.stderr = Some(stderr_content);

        println!("Job finished");
        println!("output: {:?}", job.output.stdout);
        println!("stderr: {:?}", job.output.stderr);
        println!("status: {:?}", job.status);


        let metadata = self.get_metadata(box_id).await;
        job.finished_at = Some(
            SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .unwrap()
                .as_secs()
                .try_into()
                .unwrap(),
        );
        println!("metadata: {:?}", metadata);

        job.output.memory = Some(metadata.memory);
        job.output.time = Some(metadata.time);
        job.output.exit_code = Some(metadata.exit_code);
        job.output.message = Some(metadata.message);
        job.status = determine_status(
            metadata.status,
            metadata.exit_code,
            &job.output.stdout.clone().unwrap(),
            &job.expected_output,
        );

        // job.output.result =
        //     Some(self.get_results(&job.output.stdout.clone().unwrap(), &job.expected_output));

        // Update job in Redis
        self.update_job_in_redis(job).await.unwrap();

        Ok(job.status.clone())
    }

    async fn update_job_in_redis(&self, job: &Job) -> Result<(), RedisError> {
        let job_id = job.id.to_string();
        self.redis
            .store_job(&job_id, job, None)
            .await
            .map_err(|_| RedisError::from((redis::ErrorKind::IoError, "Failed to store job")))
    }

    async fn get_metadata(&self, box_id: u64) -> Metadata {
        let metadata_file = format!("/var/local/lib/isolate/{}/box/metadata", box_id);
        let metadata = tokio::fs::read_to_string(metadata_file)
            .await
            .map_err(|_| JobStatus::RuntimeError)
            .map_err(|_| JobStatus::InternalError)
            .unwrap();

        let lines: Vec<&str> = metadata.lines().collect();

        let meta = lines.iter().map(|&pairs| {
            let mut parts = pairs.splitn(2, ':');
            let key = parts.next().unwrap();
            let value = parts.next().unwrap();
            (key, value)
        });


        let mut m: Metadata = Metadata {
            time: 0.0,
            memory: 0,
            exit_code: 0,
            message: "".to_string(),
            status: "".to_string(),
        };

        meta.for_each(|f| match f.0 {
            "time" => m.time = f.1.parse().unwrap(),
            "max-rss" => m.memory = f.1.parse().unwrap(),
            "exitcode" => m.exit_code = f.1.parse().unwrap(),
            "message" => m.message = f.1.to_string(),
            "status" => m.status = f.1.to_string(),
            _ => {}
        });

        m
    }

    // fn get_results(&self, expected: &String, output: &String) -> {
    //     if expected == output {
    //         JobResult::Accepted
    //     } else {
    //         JobResult::WrongAnswer
    //     }
    // }
}

fn determine_status(
    status: String,
    exitcode: i32,
    stdout: &String,
    expected: &String,
) -> JobStatus {
    match status.as_str() {
        "TO" => JobStatus::TimeLimitExceeded,
        "SG" => find_typeof_runtime(exitcode),
        "RE" => JobStatus::RuntimeError("NZEC".to_string()),
        "XX" => JobStatus::InternalError,
        _ if (expected.is_empty() || stdout.trim() == expected.trim()) => JobStatus::Accepted,
        _ => JobStatus::WrongAnswer,
    }
}

fn find_typeof_runtime(exitcode: i32) -> JobStatus {
    match exitcode {
        11 => JobStatus::RuntimeError("SIGSEGV".to_string()),
        25 => JobStatus::RuntimeError("SIGXFSZ".to_string()),
        8 => JobStatus::RuntimeError("SIGFPE".to_string()),
        6 => JobStatus::RuntimeError("SIGABRT".to_string()),
        _ => JobStatus::RuntimeError("Other".to_string()),
    }
}


=== ./src/vendors/mod.rs ===
pub mod isolate;
pub mod debugger;
// pub mod sqlizer;

=== ./src/vendors/sqlizer.rs ===
use std::{error::Error, fs, process::Command};
use std::fmt;
use std::path::PathBuf;

use crate::core::pool::Code;

use super::isolate::Metadata;

#[derive(Debug)]
pub enum SqlizerError {
    IoError(std::io::Error),
    DockerError(String),
    OutputMismatch,
}

impl fmt::Display for SqlizerError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            SqlizerError::IoError(e) => write!(f, "IO error: {}", e),
            SqlizerError::DockerError(e) => write!(f, "Docker error: {}", e),
            SqlizerError::OutputMismatch => write!(f, "Query output did not match expected output"),
        }
    }
}


pub struct Sqlizer {
    box_id: u128,
    sql_dir: PathBuf,
}

impl fmt::Display for Sqlizer {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "Sqlizer #{}", self.box_id)
    }
}

impl Sqlizer {
    pub fn new(code: Code) -> Result<Self, SqlizerError> {
        let box_id = code.id % 1000;
        let sql_dir = PathBuf::from(format!("/tmp/sqlizer/{}", box_id));

        fs::create_dir_all(&sql_dir)
            .map_err(SqlizerError::IoError)?;

        let paths = [
            ("query.sql", &code.source_code),
            ("correct_query.sql", &code.correct_query_code),
            ("table.sql", &code.stdin),
        ];

        // Initialize files
        for (filename, content) in paths.iter() {
            fs::write(sql_dir.join(filename), content)
                .map_err(SqlizerError::IoError)?;
        }

        // Copy script file
        let script = fs::read_to_string("./sql_script.sh")
            .map_err(SqlizerError::IoError)?;
        fs::write(sql_dir.join("sql_script.sh"), script)
            .map_err(SqlizerError::IoError)?;

        Ok(Sqlizer {
            box_id,
            sql_dir,
        })
    }

    pub fn run(&self) -> Result<Metadata, SqlizerError> {
        let output = Command::new("docker")
            .arg("run")
            .arg("-v")
            .arg(format!("{}:/sqlizer", self.sql_dir.display()))
            .arg("-v")
            .arg("/data:/data")
            .arg("sqlizer")
            .output()
            .map_err(|e| SqlizerError::DockerError(e.to_string()))?;

        if !output.status.success() {
            return Err(SqlizerError::DockerError(
                String::from_utf8_lossy(&output.stderr).to_string()
            ));
        }

        let read_file = |filename: &str| -> Result<String, SqlizerError> {
            fs::read_to_string(self.sql_dir.join(filename))
                .map_err(SqlizerError::IoError)
        };

        let user_output = read_file("user_output.sql")?;
        let expected_output = read_file("expected_output.sql")?;
        let error_output = read_file("error_output.sql")?;
        let metadata_output = read_file("metadata.json")?;

        let result = user_output == expected_output;

        let mut metadata = Metadata {
            time: 0.0,
            wall_time: 0.0,
            memory: 0,
            std_out: user_output,
            std_err: error_output,
            exit_code: if result { 0 } else { 1 },
            exit_signal: 0,
            message: if result { "Correct" } else { "Incorrect" }.to_string(),
            status: if result { "Correct" } else { "Incorrect" }.to_string(),
        };

        // Parse metadata output
        for line in metadata_output.lines() {
            let mut parts = line.split(':');
            if let (Some(key), Some(value)) = (parts.next(), parts.next()) {
                match key.trim() {
                    "User time (seconds)" => metadata.time = value.trim().parse().unwrap_or(0.0),
                    "System time (seconds)" => metadata.wall_time = value.trim().parse().unwrap_or(0.0),
                    "Maximum resident set size (kbytes)" => metadata.memory = value.trim().parse().unwrap_or(0),
                    _ => {}
                }
            }
        }

        Ok(metadata)
    }
}

=== ./src/worker/mod.rs ===
use crate::{client::redis::RedisClient, core::job::Job, vendors::isolate::IsolateExecutor};
use futures::StreamExt;
use std::{process::Command, sync::Arc};

pub struct Worker {
    redis: Arc<RedisClient>,
    isolate_executor: IsolateExecutor,
}

impl Worker {
    pub fn new(redis: RedisClient) -> Self {
        Self {
            redis: Arc::new(redis.clone()),
            isolate_executor: IsolateExecutor::new(redis),
        }
    }

    pub async fn start(&self, concurrency: usize) {
        let mut jobs_stream =
            futures::stream::repeat_with(|| self.redis.get_job_from_queue::<Job>("jobs"))
                .buffer_unordered(concurrency);

        while let Some(Ok(job)) = jobs_stream.next().await {
            let executor = self.isolate_executor.clone();

            tokio::spawn(async move {
                let max_retries = 3;
                let mut retry_count = 0;
                if let Some(mut job) = job {
                    loop {
                        let result = executor.execute(&mut job).await;
                        match result {
                            Ok(_) => {
                                println!("Job {} executed successfully", job.id);
                                break;
                            }
                            Err(e) => {
                                println!("Job {} failed: {:?}", job.id, e);
                                retry_count += 1;
                                if retry_count >= max_retries {
                                    println!("Job {} failed after {} retries", job.id, max_retries);
                                    break;
                                }
                            }
                        }
                        let box_id = job.id % 2147483647;
                        let _ = Command::new("isolate")
                            .args(&["-b", &box_id.to_string(), "--cleanup"])
                            .output()
                            .unwrap();
                    }
                }
            });
        }
    }
}


